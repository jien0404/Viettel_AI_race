# Public_103

  1. **Giáº£i thÃ­ch:**


TÆ°Æ¡ng tá»± CRFs, Linear-Chain CRFs phÃ¢n loáº¡i chuá»—i dá»±a trÃªn xÃ¡c suáº¥t $P(Y|X)Pleft( Y middle| X right)$. Vá»›i chuá»—i x cho trÆ°á»›c, CRFs sáº½ tÃ¬m ra chuá»—i y sao cho xÃ¡c suáº¥t $P(Y=y|X=x)Pleft( Y = y middle| X =  x right)$ lÃ  lá»›n nháº¥t.

$$
yÌ‚=argmaxyP(y|x)widehat{y} =  {argmax}_{y} Pleft( y middle| x right)
$$

XÃ¡c suáº¥t $P(Y|X)Pleft( Y middle| X right)$ Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ´ng qua viá»‡c Ä‘á»‹nh nghÄ©a cÃ¡c hÃ m Ä‘áº·c trÆ°ng $fkf_{k}$vÃ  $gkg_{k}$ vÃ  xÃ¡c Ä‘á»‹nh giÃ¡ trá»‹ $Î»klambda_{k}$, $Î¼kmu_{k}$. CÃ¡c trá»ng sá»‘ Ä‘Æ°á»£c tá»‘i Æ°u trong quÃ¡ trÃ¬nh huáº¥n huyá»‡n vá»›i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n. NÃ³i cÃ¡ch khÃ¡c, quÃ¡ trÃ¬nh huáº¥n luyá»‡n CRFs lÃ  quÃ¡ trÃ¬nh há»c phÃ¢n phá»‘i xÃ¡c suáº¥t $P(Y|X)Pleft( Y middle| X right)$ cá»§a táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.

Viá»‡c tá»‘i Æ°u hÃ³a cÃ¡c trá»ng sá»‘ $$
Î¸=(Î»1,â€¦,Î»k;Î¼1,â€¦,Î¼k)theta = (lambda_{1}, ldots,lambda_{k};mu_{1},ldots,mu_{k})
$$ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c tÃ¬m kiáº¿m hÃ m nÄƒng lÆ°á»£ng tá»‘i Æ°u cho mÃ´ hÃ¬nh. MÃ´ hÃ¬nh CRFs sáº½ Ä‘iá»u chá»‰nh cÃ¡c trá»ng sá»‘ Ä‘á»ƒ hÃ m Ä‘áº·c trÆ°ng pháº£n Ã¡nh chÃ­nh xÃ¡c má»‘i quan há»‡ giá»¯a chuá»—i quan sÃ¡t vÃ  chuá»—i nhÃ£n, tá»« Ä‘Ã³ Ä‘Æ°a ra dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c nháº¥t. Do Ä‘Ã³, hÃ m Ä‘áº·c trÆ°ng Ä‘Ã³ng vai trÃ² then chá»‘t trong viá»‡c xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ giá»¯a chuá»—i quan sÃ¡t x vÃ  chuá»—i nhÃ£n y. Viá»‡c lá»±a chá»n vÃ  thiáº¿t káº¿ hÃ m Ä‘áº·c trÆ°ng phÃ¹ há»£p vá»›i bÃ i toÃ¡n cá»¥ thá»ƒ lÃ  ráº¥t quan trá»ng Ä‘á»ƒ Ä‘áº£m báº£o mÃ´ hÃ¬nh cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c máº«u quan trá»ng tá»« dá»¯ liá»‡u vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c.

### 2\. Huáº¥n luyá»‡n 

Viá»‡c huáº¥n luyá»‡n thÆ°á»ng sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p MLE (Maximum Likelihood Estimation) Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c trá»ng sá»‘ $$
Î¸=(Î»1,â€¦,Î»k;Î¼1,â€¦,Î¼k)theta = (lambda_{1}, ldots,lambda_{k};mu_{1},ldots,mu_{k})
$$ tá»« táº­p huáº¥n luyá»‡n $$
D={(x(ğ•š),y(ğ•š))}i=1ND = left{ left( x^{(mathbb{i})},y^{(mathbb{i})} right) right}_{i = 1}^{N}
$$. Má»¥c tiÃªu cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n lÃ  tÃ¬m ra bá»™ trá»ng sá»‘ $Î¸theta$ Ä‘á»ƒ hÃ m má»¥c tiÃªu log-likelihood $L(Î¸)L(theta)$ lÃ  lá»›n nháº¥t.

$$
L(Î¸)=âˆ‘i=1Nlog(PÎ¸(y(ğ•š)|x(ğ•š)))L(theta) = sum_{i = 1}^{N}{logleft( P_{theta}left( y^{(mathbb{i})} middle| x^{(mathbb{i})} right) right)}
$$

$$
=âˆ‘i=1N(âˆ‘t=1n(âˆ‘kÎ»kfk(ytâˆ’1(i),yt(i),x(ğ•š),t)+âˆ‘kÎ¼kgk(yt(i),x(ğ•š),t))âˆ’log(ZÎ¸(x(ğ•š))))=  sum_{i = 1}^{N}left( sum_{t = 1}^{n}left( sum_{k}^{}{{lambda_{k}f}_{k}left( y_{t - 1}^{(i)}, y_{t}^{(i)}, x^{(mathbb{i})},t right)} + sum_{k}^{}{mu_{k}g_{k}left( y_{t}^{(i)}, x^{(mathbb{i})},t right)} right)  -  logleft( Z_{theta}left( x^{(mathbb{i})} right) right) right)
$$

Viá»‡c tá»‘i Æ°u hÃ³a hÃ m má»¥c tiÃªu cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u dá»±a trÃªn viá»‡c tÃ­nh gradient nhÆ° Gradient Descent, Stochastic Gradient Descent (SGD), L-BFGS (Limited-memory BFGS). Do Ä‘Ã³ chÃºng ta cáº§n tÃ­nh gradient cá»§a $L(Î¸)L(theta)$.

$$
âˆ‚Lâˆ‚Î»k=âˆ‘i=1N(âˆ‘t=1nfk(ytâˆ’1(i),yt(i),x(ğ•š),t)âˆ’1ZÎ¸(x(ğ•š))âˆ‚ZÎ¸âˆ‚Î»k)frac{partial Ltext{  }}{text{ }partiallambda_{ktext{  }}} = text{ }sum_{i = 1}^{N}left( sum_{t = 1}^{n}{f_{k}left( y_{t - 1}^{(i)}, y_{t}^{(i)}, x^{(mathbb{i})},t right)}  -  frac{1}{Z_{theta}left( x^{(mathbb{i})} right)}frac{partial Z_{theta}}{partiallambda_{ktext{  }}} right)
$$

$$
1ZÎ¸(x(ğ•š))âˆ‚ZÎ¸âˆ‚Î»k=1ZÎ¸(x(ğ•š))âˆ‘yâ€²âˆˆÎ©y(âˆ‘t=1nfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)eâˆ’E(x(ğ•š),yâ€²))frac{1}{Z_{theta}left( x^{(mathbb{i})} right)}frac{partial Z_{theta}text{  }}{text{ }partiallambda_{ktext{  }}} = frac{1}{Z_{theta}left( x^{(mathbb{i})} right)}sum_{y^{'} in  Omega_{y}}^{}left( sum_{t = 1}^{n}{f_{k}left( {y'}_{t - 1}, {y'}_{t}, x^{(mathbb{i})},t right)}e^{- Eleft( x^{(mathbb{i})},y^{'} right)} right)
$$

$$
=âˆ‘yâ€²âˆˆÎ©y(âˆ‘t=1nfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)eâˆ’E(x(ğ•š),yâ€²)ZÎ¸(x(ğ•š)))= sum_{y^{'} in  Omega_{y}}^{}left( sum_{t = 1}^{n}{f_{k}left( {y'}_{t - 1}, {y'}_{t}, x^{(mathbb{i})},t right)}frac{e^{- Eleft( x^{(mathbb{i})},y^{'} right)}}{Z_{theta}left( x^{(mathbb{i})} right)} right)
$$
$$
=âˆ‘yâ€²âˆˆÎ©y(âˆ‘t=1nfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š)))= sum_{y^{'} in  Omega_{y}}^{}left( sum_{t = 1}^{n}{f_{k}left( {y'}_{t - 1}, {y'}_{t},x^{(mathbb{i})},t right)}Pleft( y' middle| x^{(mathbb{i})} right) right)
$$
$$
=âˆ‘t=1nâˆ‘yâ€²âˆˆÎ©yfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š))=  sum_{t = 1}^{n}{sum_{y^{'} in  Omega_{y}}^{}{f_{k}left( {y'}_{t - 1}, {y'}_{t},x^{(mathbb{i})},t right)Pleft( y' middle| x^{(mathbb{i})} right)}}
$$

$$
â‡’âˆ‚Lâˆ‚Î»k=âˆ‘i=1Nâˆ‘t=1n(fk(ytâˆ’1(i),yt(i),x(ğ•š),t)âˆ’âˆ‘yâ€²âˆˆÎ©yfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š)))Rightarrow frac{partial Ltext{  }}{text{ }partiallambda_{ktext{  }}} = text{ }sum_{i = 1}^{N}{sum_{t = 1}^{n}left( f_{k}left( y_{t - 1}^{(i)}, y_{t}^{(i)}, x^{(mathbb{i})},t right) - sum_{y^{'} in  Omega_{y}}^{}{f_{k}left( {y'}_{t - 1}, {y'}_{t}, x^{(mathbb{i})},t right)Pleft( y^{'} middle| x^{(mathbb{i})} right)} right)}
$$

Gá»i $Ex(fk)E_{x}left( f_{k} right)$ lÃ  kÃ¬ vÃ²ng hÃ m Ä‘áº·c trÆ°ng $fkf_{k}$ theo phÃ¢n phá»‘i xÃ¡c suáº¥t $P(y|x)Pleft( y middle| x right)$:

$$
Ex(fk)=âˆ‘t=1nâˆ‘yâ€²âˆˆÎ©yfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š))E_{x}left( f_{k} right) =  sum_{t = 1}^{n}{sum_{y^{'} in  Omega_{y}}^{}{f_{k}left( {y'}_{t - 1}, {y'}_{t}, x^{(mathbb{i})},t right)Pleft( y^{'} middle| x^{(mathbb{i})} right)}}
$$

$$
â‡’âˆ‚Lâˆ‚Î»k=âˆ‘i=1N(âˆ‘t=1nfk(ytâˆ’1(i),yt(i),x(ğ•š),t)+Ex(i)(fk))Rightarrow frac{partial Ltext{  }}{text{ }partiallambda_{ktext{  }}} = text{ }sum_{i = 1}^{N}left( sum_{t = 1}^{n}{f_{k}left( y_{t - 1}^{(i)}, y_{t}^{(i)}, x^{(mathbb{i})},t right)} +  E_{x^{(i)}}left( f_{k} right) right)
$$

TÆ°Æ¡ng tá»± ta cÅ©ng cÃ³ gradient cho $Î¼kmu_{k}$:

$$
Ex(gk)=âˆ‘t=1nâˆ‘yâ€²âˆˆÎ©ygk(yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š))E_{x}left( g_{k} right) =  sum_{t = 1}^{n}{sum_{y^{'} in  Omega_{y}}^{}{g_{k}left( {y'}_{t}, x^{(mathbb{i})},t right)Pleft( y^{'} middle| x^{(mathbb{i})} right)}}
$$

$$
âˆ‚Lâˆ‚Î¼k=âˆ‘i=1N(âˆ‘t=1ngk(yt(i),x(ğ•š),t)+Ex(i)(gk))frac{partial Ltext{  }}{text{ }partialmu_{k}} = text{ }sum_{i = 1}^{N}left( sum_{t = 1}^{n}{g_{k}left( y_{t}^{(i)}, x^{(mathbb{i})},t right)} +  E_{x^{(i)}}left( g_{k} right) right)
$$

Náº¿u tÃ­nh trá»±c tiáº¿p kÃ¬ vá»ng cá»§a cÃ¡c hÃ m Ä‘áº·c trÆ°ng tá»« cÃ´ng thá»©c trÃªn thÃ¬ Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n sáº½ lÃ  hÃ m mÅ© $$
(O(nÃ—|ğ’´|n))left( Oleft( n times left| mathcal{Y} right|^{n} right) right)
$$. Do Ä‘Ã³ khÃ´ng kháº£ thi khi sá»‘ lÆ°á»£ng nhÃ£n vÃ  bá»™ dá»¯ liá»‡u lá»›n. Äá»ƒ giáº£m Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n ta biáº¿n Ä‘á»•i cÃ´ng thá»©c trÃªn thÃ nh dáº¡ng sau:

$$
Ex(fk)=âˆ‘t=1nâˆ‘yâ€²âˆˆÎ©yfk(yâ€²tâˆ’1,yâ€²t,x(ğ•š),t)P(yâ€²|x(ğ•š))E_{x}left( f_{k} right) =  sum_{t = 1}^{n}{sum_{y^{'} in  Omega_{y}}^{}{f_{k}left( {y'}_{t - 1}, {y'}_{t}, x^{(mathbb{i})},t right)Pleft( y^{'} middle| x^{(mathbb{i})} right)}}
$$
$$
=âˆ‘t=1nâˆ‘yâ€²,yâ€³âˆˆğ’´fk(yâ€²,yâ€³,x(ğ•š),t)P(Ytâˆ’1=yâ€²,Yt=yâ€³|x(ğ•š))= sum_{t = 1}^{n}{sum_{y^{'}, y^{''} in  mathcal{Y}}^{}{f_{k}left( y', y'', x^{(mathbb{i})},t right)Pleft( Y_{t - 1} = y^{'}, Y_{t} = y'' middle| x^{(mathbb{i})} right)}}
$$

Trong Ä‘Ã³ $$
P(Ytâˆ’1=yâ€²,Yt=yâ€³|x(ğ•š))Pleft( Y_{t - 1} = y^{'}, Y_{t} = y'' middle| x^{(mathbb{i})} right)
$$ lÃ  xÃ¡c xuáº¥t biÃªn cá»§a $Ytâˆ’1=yâ€²,Yt=yâ€³Y_{t - 1} = y^{'}, Y_{t} = y''$ khi biáº¿t chuá»—i quan sÃ¡t $x(ğ•š)x^{(mathbb{i})}$, tá»©c xÃ¡c suáº¥t Ä‘á»ƒ cáº·p nhÃ£n $(yâ€²,yâ€³)(y', y'')$ Ä‘Æ°á»£c gÃ¡n táº¡i vá»‹ trÃ­ t-1 vÃ  t khi biáº¿t $x(ğ•š)x^{(mathbb{i})}$ mÃ  khÃ´ng quan tÃ¢m Ä‘áº¿n cÃ¡c nhÃ£n cÃ²n láº¡i. XÃ¡c suáº¥t biÃªn nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­nh trong thá»i gian Ä‘a thá»©c báº±ng thuáº­t toÃ¡n Forward-Backward.

TÆ°Æ¡ng tá»± cho $Î¼kmu_{k}$:

$$
Ex(gk)=âˆ‘t=1nâˆ‘yâ€²âˆˆğ’´gk(yâ€²,x(ğ•š),t)P(Yt=yâ€²|x(ğ•š))E_{x}left( g_{k} right) =  sum_{t = 1}^{n}{sum_{y^{'} in  mathcal{Y}}^{}{g_{k}left( y', x^{(mathbb{i})},t right)Pleft( Y_{t} = y^{'} middle| x^{(mathbb{i})} right)}}
$$

### 3\. Thuáº­t toÃ¡n Forward-Backward Ã¡p dá»¥ng trong tÃ­nh gradient

![A diagram of a network AI-generated content may be incorrect.](images/image1.png)

HiÌ€nh 3.1. Minh há»a thuáº­t toÃ¡n Forward-Backward trong viá»‡c xÃ¡c suáº¥t biÃªn táº¡i 1 nÃºt

Ã tÆ°á»Ÿng cá»§a thuáº­t toÃ¡n Forward-Backward lÃ  tÃ­nh xÃ¡c suáº¥t biÃªn dá»±a vÃ o viá»‡c tÃ­nh xÃ¡c suáº¥t tiáº¿n $Î±i(x)alpha_{i}(x)$ vÃ  xÃ¡c suáº¥t lÃ¹i $Î²i(x)beta_{i}(x)$. HÃ¬nh 8 mÃ´ táº£ Ã½ tÆ°á»Ÿng tÃ­nh xÃ¡c suáº¥t biÃªn $P(Y2=v|x)Pleft( Y_{2} =  v middle| x right)$ vÃ  hÃ¬nh 9 mÃ´ táº£ Ã½ tÆ°á»Ÿng cÃ¡ch tÃ­nh xÃ¡c suáº¥t biÃªn $$
P(Ytâˆ’1=yâ€²,Yt=yâ€³|x)Pleft( Y_{t - 1} = y^{'}, Y_{t} = y'' middle| x right)
$$ cho bÃ i toÃ¡n POS. Má»—i má»™t Ä‘Æ°á»ng Ä‘i tá»« <S> Ä‘áº¿n <T> lÃ  1 trÆ°á»ng há»£p cá»§a chuá»—i Y. Trá»ng sá»‘ cá»§a cá»§a má»—i cáº¡nh Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c $Mi(Cj,Ck|x)M_{i}left( C_{j},C_{k} middle| x right)$ Ä‘Ã£ trÃ¬nh bÃ y á»Ÿ pháº§n trÆ°á»›c thá»ƒ hiá»‡n kháº£ nÄƒng nhÃ£n cá»§a tá»« liá»n ká» khi biáº¿t trÆ°á»›c nhÃ£n, trá»ng sá»‘ cá»§a 1 Ä‘Æ°á»ng Ä‘i lÃ  tÃ­ch cÃ¡c trá»ng sá»‘ cáº¡nh mÃ  Ä‘Æ°á»ng Ä‘i qua.

$$
pÎ¸(Y=y|X=x)=pÎ¸(pathy|X=x)=Trá»ngsá»‘cá»§apathyZÎ¸(x)p_{theta}left( Y = y middle|  X = x right) =  p_{theta}left( path_{y} middle|  X = x right) =  frac{Trá»ng sá»‘ cá»§a path_{y}}{Z_{theta}(x)}
$$

XÃ¡c suáº¥t biÃªn $P(Y2=v|x)Pleft( Y_{2} =  v middle| x right)$ sáº½ lÃ  tá»•ng xÃ¡c suáº¥t cá»§a táº¥t cáº£ cÃ¡c Ä‘Æ°á»ng Ä‘i Ä‘i qua v táº¡i $Y2Y_{2}$ hay tá»•ng trá»ng sá»‘ cÃ¡c Ä‘Æ°á»ng Ä‘i Ä‘Ã³. Ta cÃ³ thá»ƒ phÃ¢n tÃ­ch tá»•ng nÃ y thÃ nh tÃ­ch cá»§a 2 tá»•ng $Î±2(v|x)alpha_{2}left( v middle| x right)$ vÃ  $Î²2(v|x)beta_{2}left( v middle| x right)$.

$$
P(Y2=v|x)=Î±2(v|x)Ã—Î²2(v|x)Pleft( Y_{2} =  v middle| x right) =  alpha_{2}left( v middle| x right) times beta_{2}left( v middle| x right)
$$

Trong Ä‘Ã³ $Î±2(v|x)alpha_{2}left( v middle| x right)$ lÃ  tá»•ng trá»ng sá»‘ táº¥t cáº£ cÃ¡c Ä‘Æ°á»ng Ä‘i tá»« <S> Ä‘áº¿n v táº¡i $Y2Y_{2}$, $Î²2(v|x)beta_{2}left( v middle| x right)$ lÃ  tá»•ng trá»ng sá»‘ táº¥t cáº£ cÃ¡c Ä‘Æ°á»ng Ä‘i tá»« v táº¡i $Y2Y_{2}$ Ä‘áº¿n <T>.

Äá»ƒ tÃ­nh $Î±2(v|x)alpha_{2}left( v middle| x right)$ ta sáº½ tÃ­nh $Î±1alpha_{1}$ cá»§a táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ cá»§a Y1 rá»“i nhÃ¢n vá»›i trá»ng sá»‘ chuyá»ƒn Ä‘á»•i thÃ nh nhÃ£n v tÆ°Æ¡ng á»©ng vá»›i tá»«ng giÃ¡ trá»‹ (v => v, n => v, p => v, d => v). NhÆ° váº­y thÃ¬ $Î±ialpha_{i}$ sáº½ Ä‘Æ°á»£c tÃ­nh dá»±a theo $Î±iâˆ’1alpha_{i - 1}$ vÃ  quÃ¡ trÃ¬nh nÃ y lÃ  quÃ¡ trÃ¬nh tiáº¿n cá»§a thuáº­t toÃ¡n Forward-Backward. TÆ°Æ¡ng tá»± $Î²ibeta_{i}$ cÅ©ng Ä‘Æ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn quy hoáº¡ch Ä‘á»™ng vÃ  quÃ¡ trÃ¬nh nÃ y lÃ  quÃ¡ trÃ¬nh lÃ¹i.

Tá»•ng quÃ¡t, ta cÃ³ chuá»—i $Y=(Y0,â€¦,Yn)Y =  left( Y_{0}, ldots,Y_{n} right)$, gá»i $$
Yi:j=(Yi,â€¦,Yj)vá»›i0â‰¤i<jâ‰¤nY_{i:j} =  left( Y_{i}, ldots,Y_{j} right) vá»›i 0 leq i < j leq n
$$.

Ta cÃ³:

$$
Î±t(Yt=yâ€²|x)={âˆ‘y0:tâˆ’1â€²âˆi=1tMi(yâ€²iâˆ’1,yâ€²i|x),vá»›i1<tâ‰¤nM1(<Start>,yâ€²1|x),vá»›it=1alpha_{t}left( Y_{t} = y^{'} middle| x right) = left{ begin{array}{r}
sum_{y_{0:t - 1}^{'}}^{}{prod_{i = 1}^{t}{M_{i}left( {y^{'}}_{i - 1},{y^{'}}_{i} middle| x right)}},  vá»›i 1 < t leq n  
M_{1}left( < Start > ,{y^{'}}_{1} middle| x right) ,  vá»›i t = 1
end{array} right.
$$

$$
Î²t(Yt=yâ€²|x)={âˆ‘yt+1:nâ€²âˆi=t+1nMi(yâ€²iâˆ’1,yâ€²i|x),vá»›i1â‰¤t<nâˆ’1âˆ‘yâ€³âˆˆğ’´Mt(yâ€²,yâ€³|x),vá»›it=nâˆ’11,vá»›it=nbeta_{t}left( Y_{t} = y^{'} middle| x right) =  left{ begin{array}{r}
sum_{y_{t + 1:n}^{'}}^{}{prod_{i = t + 1}^{n}{M_{i}left( {y^{'}}_{i - 1},{y^{'}}_{i} middle| x right)}},   vá»›i 1 leq t < n - 1 
sum_{y^{''} in  mathcal{Y}}^{}{M_{t}left( y',y'' middle| x right)},    vá»›i t = n - 1 
1 ,                                  vá»›i t = n
end{array} right.
$$

Ta chá»©ng minh $$
Î±t(Yt=yâ€²|x)=âˆ‘yâ€²tâˆ’1âˆˆğ’´Î±tâˆ’1(Ytâˆ’1=yâ€²tâˆ’1|x)Ã—Mt(yâ€²tâˆ’1,yâ€²|x)alpha_{t}left( Y_{t} = y^{'} middle| x right) =  sum_{{y^{'}}_{t - 1} in mathcal{Y}}^{}{alpha_{t - 1}left( Y_{t - 1} = {y^{'}}_{t - 1} middle| x right)} times M_{t}left( {y^{'}}_{t - 1},y^{'} middle| x right)
$$ vá»›i $1<tâ‰¤n 1 < t leq n$, tháº­t váº­y:

$$
Î±t(Yt=yâ€²|x)=âˆ‘y0:tâˆ’2â€²âˆ‘yâ€²tâˆ’1âˆˆğ’´âˆi=1tâˆ’1Mi(yâ€²iâˆ’1,yâ€²i|x)Ã—Mt(yâ€²tâˆ’1,yâ€²t|x)alpha_{t}left( Y_{t} = y^{'} middle| x right) = sum_{y_{0:t - 2}^{'}}^{}{sum_{{y^{'}}_{t - 1} in mathcal{Y}}^{}{prod_{i = 1}^{t - 1}{M_{i}left( {y^{'}}_{i - 1},{y^{'}}_{i} middle| x right) times}}}M_{t}left( {y^{'}}_{t - 1},{y^{'}}_{t} middle| x right)
$$
$$
=âˆ‘yâ€²tâˆ’1âˆˆğ’´(âˆ‘y0:tâˆ’2â€²âˆi=1tâˆ’1Mi(yâ€²iâˆ’1,yâ€²i|x))Ã—Mt(yâ€²tâˆ’1,yâ€²t|x)= sum_{{y^{'}}_{t - 1} in mathcal{Y}}^{}left( sum_{y_{0:t - 2}^{'}}^{}{prod_{i = 1}^{t - 1}{M_{i}left( {y^{'}}_{i - 1},{y^{'}}_{i} middle| x right)}} right) times M_{t}left( {y^{'}}_{t - 1},{y^{'}}_{t} middle| x right)
$$
$$
=âˆ‘yâ€²tâˆ’1âˆˆğ’´Î±tâˆ’1(Ytâˆ’1=yâ€²tâˆ’1|x)Ã—Mt(yâ€²tâˆ’1,yâ€²|x)=  sum_{{y^{'}}_{t - 1} in mathcal{Y}}^{}{alpha_{t - 1}left( Y_{t - 1} = {y^{'}}_{t - 1} middle| x right)} times M_{t}left( {y^{'}}_{t - 1},y^{'} middle| x right)
$$

TÆ°Æ¡ng tá»±, vá»›i$1â‰¤t<nâˆ’1 1 leq t < n - 1$ta cÅ©ng cÃ³:

$$
Î²t(Yt=yâ€²|x)=âˆ‘yâ€²t+1âˆˆğ’´Mt+1(yâ€²,yâ€²t+1|x)Î²t+1(Yt+1=yâ€²t+1|x)beta_{t}left( Y_{t} = y^{'} middle| x right) =  sum_{{y^{'}}_{t + 1} in mathcal{Y}}^{}{{M_{t + 1}left( y^{'}, {y^{'}}_{t + 1} middle| x right)beta}_{t + 1}left( Y_{t + 1} = {y^{'}}_{t + 1} middle| x right)}
$$

Vá»›i cÃ¡ch biá»ƒu diá»…n dÆ°á»›i dáº¡ng ma tráº­n cÃ´ng thá»©c $$
Î±t(Yt=yâ€²|x)alpha_{t}left( Y_{t} = y^{'} middle| x right)
$$ vÃ  $$
Î²t(Yt=yâ€²|x)beta_{t}left( Y_{t} = y^{'} middle| x right)
$$ cÃ³ thá»ƒ biá»ƒu diá»…n dÆ°á»›i dáº¡ng tÃ­ch ma tráº­n vÃ  vector vá»›i $Mi(x)<Start>{M_{i}(x)}_{< Start >}$ lÃ  vetor hÃ ng á»©ng vÃ³i nhÃ£n $<Start>< Start >$, $1|ğ’´â€²|Ã—11_{left| mathcal{Y'} right| times 1}$ lÃ  ma tráº­n cÃ¡c giÃ¡ trá»‹ 1 kÃ­ch thÆ°á»›c $|ğ’´â€²|Ã—1left| mathcal{Y'} right| times 1$:

$$
Î±t(Yt=yâ€²|x)={(Mi(x)<Start>Ã—âˆi=2tMi(x))0,yâ€²,vá»›i1<tâ‰¤nMi(x)<Start>,yâ€²,vá»›it=1alpha_{t}left( Y_{t} = y^{'} middle| x right) = left{ begin{array}{r}
left( {M_{i}(x)}_{< Start >} times prod_{i = 2}^{t}{M_{i}(x)} right)_{0,y'}    , vá»›i 1 < t leq n  
{M_{i}(x)}_{< Start > ,y^{'}} ,                           vá»›i t = 1
end{array} right.
$$

$$
Î²t(Yt=yâ€²|x)={((âˆi=1t+1Mi(x))Ã—1|ğ’´â€²|Ã—1)yâ€²,0,vá»›i1â‰¤t<n1,vá»›it=nbeta_{t}left( Y_{t} = y^{'} middle| x right) = left{ begin{array}{r}
left( left( prod_{i = 1}^{t + 1}{M_{i}(x)} right){times 1}_{left| mathcal{Y'} right| times 1} right)_{y', 0}    , vá»›i 1 leq t < n  
1 ,                                              vá»›i t = n
end{array} right.
$$

CÃ´ng thá»©c xÃ¡c xuáº¥t biÃªn biá»ƒu diá»…n báº±ng xÃ¡c suáº¥t tiáº¿n vÃ  lÃ¹i cÃ³ dáº¡ng:

$$
P(Yt=yâ€²|x)=Î±t(Yt=yâ€²|x)Ã—Î²t(Yt=yâ€²|x)ZÎ¸(x)Pleft( Y_{t} = y^{'} middle| x right) = frac{alpha_{t}left( Y_{t} = y^{'} middle| x right) times beta_{t}left( Y_{t} = y^{'} middle| x right)}{Z_{theta}(x)}
$$

![A diagram of a neural network AI-generated content may be incorrect.](images/image2.png)

HiÌ€nh 3.2. Minh há»a thuáº­t toÃ¡n Forward-Backward trong viá»‡c xÃ¡c suáº¥t biÃªn táº¡i 1 cáº¡nh

TÆ°Æ¡ng tá»± vá»›i xÃ¡c suáº¥t biÃªn $$
P(Ytâˆ’1=yâ€²,Yt=yâ€³|x)Pleft( Y_{t - 1} = y^{'}, Y_{t} = y'' middle| x right)
$$, ta cÃ³:

$$
P(Ytâˆ’1=yâ€²,Yt=yâ€³|x)=Î±tâˆ’1(Ytâˆ’1=yâ€²|x)Ã—Mt(yâ€²,yâ€³|x)Ã—Î²t(Yt=yâ€³|x)ZÎ¸(x)Pleft( Y_{t - 1} = y^{'}, Y_{t} = y'' middle| x right) =  frac{alpha_{t - 1}left( Y_{t - 1} = y^{'} middle| x right) times M_{t}left( y',y'' middle| x right) times beta_{t}left( Y_{t} = y^{''} middle| x right)}{Z_{theta}(x)}
$$

Báº±ng phÆ°Æ¡ng phÃ¡p quy hoáº¡ch Ä‘á»™ng, ta cÃ³ thá»ƒ tÃ­nh cÃ¡c xÃ¡c suáº¥t biÃªn vá»›i Ä‘á»™ phá»©c táº¡p $$
O(nÃ—|ğ’´|2)Oleft( n times left| mathcal{Y} right|^{2} right)
$$ vÃ  chÃ­nh lÃ  Ä‘á»™ phá»©c táº¡p khi tÃ­nh kÃ¬ vá»ng cá»§a cÃ¡c hÃ m Ä‘áº·c trÆ°ng.

### 4\. Thuáº­t toÃ¡n Viterbi Ã¡p dá»¥ng trong suy luáº­n Linear-Chain CRFs

XÃ¡c Ä‘á»‹nh chuá»—i $yÌ‚widehat{y}$ cÃ³ xÃ¡c suáº¥t xáº£y ra cao nháº¥t khi biáº¿t x:

$$
yÌ‚=argmaxyP(y|x)=argmaxyâˆi=1nMi(yiâˆ’1,yi|x)ZÎ¸(x)widehat{y} =  {argmax}_{y} Pleft( y middle| x right) =  {argmax}_{y}frac{prod_{i = 1}^{n}{M_{i}left( y_{i - 1},y_{i} middle| x right)}}{Z_{theta}(x)}
$$

VÃ¬ $ZÎ¸(x)Z_{theta}(x)$ lÃ  háº±ng sá»‘ khi biáº¿t nÃªn viá»‡c xÃ¡c Ä‘á»‹nh chuá»—i $yÌ‚widehat{y}$ cÃ³ xÃ¡c suáº¥t xáº£y ra cao nháº¥t khi biáº¿t x tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i xÃ¡c Ä‘á»‹nh chuá»—i $yÌ‚widehat{y}$ Ä‘á»ƒ $$
âˆi=1nMi(yiâˆ’1,yi|x)prod_{i = 1}^{n}{M_{i}left( y_{i - 1},y_{i} middle| x right)}
$$ lá»›n nháº¥t:

$$
yÌ‚=argmaxyâˆi=1nMi(yiâˆ’1,yi|x)widehat{y} =  {argmax}_{y}prod_{i = 1}^{n}{M_{i}left( y_{i - 1},y_{i} middle| x right)}
$$

Viá»‡c tÃ¬m $yÌ‚widehat{y}$ cÃ³ thá»ƒ tÃ­nh trong thá»i gian $$
O(nÃ—|ğ’´|2)Oleft( n times left| mathcal{Y} right|^{2} right)
$$ vá»›i thuáº­t toÃ¡n quy hoáº¡ch Ä‘á»™ng Viterbi. Thuáº­t toÃ¡n Viterbi Ä‘Æ°á»£c mÃ´ táº£ báº±ng mÃ£ giáº£ trong hÃ¬nh 10.

![A screenshot of a math program AI-generated content may be incorrect.](images/image3.png)

HiÌ€nh 4.1: Thuáº­t toÃ¡n Viterbi cho suy luáº­n Linear-chain CRFs

$Mi(x)M_{i}(x)$ lÃ  ma tráº­n Ä‘Ã£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong pháº§n 3 vá»›i hÃ ng 0 vÃ  cá»™t 0 tÆ°Æ¡ng á»©ng vá»›i nhÃ£n <Start>.

![A diagram of a neural network AI-generated content may be incorrect.](images/image4.png)

HiÌ€nh 4.2: HÃ¬nh minh há»a thuáº­t toÃ¡n Viterbi cho POS

HÃ¬nh 4.2 lÃ  minh há»a quÃ¡ trÃ¬nh suy luáº­n Viterbi cho POS. Giáº£ sá»­ sau khi huáº¥n luyá»‡n ta Ä‘Ã£ cÃ³ Ä‘Æ°á»£c trá»ng sá»‘ cá»§a cÃ¡c Ä‘Æ°á»ng Ä‘i $MiM_{i}$. Vá»›i Ä‘áº§u cÃ¢u Ä‘áº§u vÃ o cÃ³ 4 tá»«, vÃ  cáº§n gÃ¡n nhÃ£n cho 4 tá»« nÃ y má»™t nhÃ£n tá»« loáº¡i lÃ  1 trong 4 giÃ¡ trá»‹: v, n, p, d. á» Ä‘Ã¢y, má»—i má»™t miá»n tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 1 tá»« cáº§n Ä‘Æ°á»£c gÃ¡n nhÃ£n vÃ  sá»‘ Ä‘á»‰nh trong miá»n lÃ  nhÃ£n cÃ³ thá»ƒ cÃ³ cá»§a tá»«, vÃ­ dá»¥, miá»n Y1 cÃ³ 4 Ä‘á»‰nh lÃ  v, n, p, d tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i 4 giÃ¡ trá»‹ cÃ³ thá»ƒ gÃ¡n cho tá»« Ä‘áº§u tiÃªn cá»§a cÃ¢u. Má»™t Ä‘Æ°á»ng Ä‘i há»£p lá»‡ lÃ  Ä‘Æ°á»ng Ä‘i Ä‘i qua duy nháº¥t má»™t Ä‘á»‰nh trong má»—i miá»n. Thuáº­t toÃ¡n Viterbi sáº½ tÃ¬m Ä‘Æ°á»ng sao cho trá»ng sá»‘ lÃ  lá»›n nháº¥t (tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i xÃ¡c suáº¥t chuá»—i nhÃ£n lÃ  lá»›n nháº¥t.

Ã tÆ°á»Ÿng cá»§a Viterbi lÃ  Ä‘Æ°á»ng Ä‘i lá»›n nháº¥t Ä‘áº¿n má»™t Ä‘á»‰nh sáº½ bao gá»“m Ä‘Æ°á»ng Ä‘i lá»›n nháº¥t Ä‘áº¿n Ä‘á»‰nh trÆ°á»›c nÃ³. Xuáº¥t phÃ¡t tá»« Ã½ tÆ°á»Ÿng nÃ y, Ä‘á»ƒ tÃ¬m Ä‘Æ°á»ng Ä‘i lá»›n nháº¥t Ä‘áº¿n miá»n Y4, ta sáº½ tÃ­nh Ä‘Æ°á»ng Ä‘i lá»›n nháº¥t Ä‘áº¿n cÃ¡c Ä‘á»‰nh cá»§a miá»n Y3, sau Ä‘Ã³ tá»« cÃ¡c Ä‘á»‰nh cá»§a Y3 ta tÃ­nh trá»ng sá»‘ Ä‘áº¿n cÃ¡c Ä‘á»‰nh cá»§a Y4 vÃ  chá»n ra Ä‘Æ°á»ng Ä‘i cÃ³ trá»ng sá»‘ lá»›n nhÃ¢t. TÆ°Æ¡ng tá»± Ä‘Æ°á»ng Ä‘i cÃ³ trá»ng sá»‘ lá»›n nháº¥t Ä‘áº¿n cÃ¡c Ä‘á»‰nh trong Y3 cÃ³ thá»ƒ tÃ­nh qua Ä‘Æ°á»ng Ä‘i cÃ³ trá»ng sá»‘ lá»›n nháº¥t Ä‘áº¿n cÃ¡c Ä‘á»‰nh trong Y2, â€¦.